{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "360124d4-d882-4338-a45a-d1ff2887f619",
   "metadata": {},
   "source": [
    "### Defalut Setting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44bc3365-8102-4433-a0f8-63e3b25d8d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os \n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer, LlamaTokenizerFast, BitsAndBytesConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoTokenizer, TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "from transformers import GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e08771a-c0bb-42e1-8508-9348c3a134a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_path = os.getcwd()\n",
    "data_path = os.path.join(default_path, '../../data')\n",
    "model_path = os.path.join(default_path, '../../models')\n",
    "local_mistral_dir = os.path.join(model_path, \"mistral_origin\")\n",
    "config_path = os.path.join(default_path, '../../config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54aa45f1-ffda-4d92-ae87-cdbcf969bae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "632546be-5413-4774-bd50-f77ba2a1462f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f59c2744-8f18-4ba3-9d81-10ffce94bc01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 100000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 5140\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"kaitchup/ultrachat-100k-flattened\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47c3ff5e-60a7-4d31-84e2-baefbd7aa20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "684d09f8-0729-4a3c-aa14-0fa465fd58ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"### Human: Create a salsa song with lyrics that capture the intensity and fervor of a passionate love affair between two people. The song should have a fast-paced tempo and incorporate traditional salsa instrumentation such as brass, percussion, and piano. The lyrics should paint a vivid picture of the emotions involved in a passionate romance, including love, desire, yearning, and heartbreak. Feel free to draw inspiration from real-life experiences or fictional narratives. At the end of the song, listeners should be left feeling captivated and moved by the powerful message of the song.### Assistant: Verse 1:\\nDesde el momento en que te vi\\nYo supe que ibas a ser para mí\\nTu cariño me envuelve \\nCon tu amor siempre quiero seguir\\n\\nChorus:\\nEl fuego arde en mi pecho\\nCuando estoy contigo, mi amor\\nEste romance es intenso\\nY nunca se acabará, jamás\\n\\nVerse 2:\\nTu sonrisa me encanta\\nY tus ojos me hacen sentir \\nQue eres mi otra mitad\\nY no puedo vivir sin ti \\n\\nChorus:\\nEl fuego arde en mi pecho\\nCuando estoy contigo, mi amor\\nEste romance es intenso\\nY nunca se acabará, jamás\\n\\nBridge:\\nPero a pesar de todo\\nSiento que algo nos separa\\nDime, corazón, ¿qué pasa?\\n¿Será que me estás dejando?\\n\\nChorus:\\nEl fuego arde en mi pecho\\nCuando estoy contigo, mi amor\\nEste romance es intenso\\nY nunca se acabará, jamás\\n\\nOutro:\\nAunque el camino es difícil\\nNo voy a perder mi fe\\nEste fuego que siento por ti\\nSiempre vivirá en mí.### Human: That's a great start! Can you add more descriptive words to capture the intensity and passion of the romance? Also, can you incorporate some metaphors and imagery to really make the lyrics pop?### Assistant: Verse 1:\\nDesde el momento en que te vi\\ntu mirada me atrapó, no pude resistir\\nen tus brazos, sentí la felicidad\\nde un amor que desde siempre quise encontrar\\n\\nChorus:\\nEl fuego de tu amor me quema\\ncada noche sueño con tenerte\\nesta pasión ardiente nos une\\nnuestro amor es un fuego eterno\\n\\nVerse 2:\\nTus labios me enloquecen\\ncada beso me hace temblar\\nno me importa el tiempo, ni la distancia\\nporque mi corazón siempre te va a amar\\n\\nChorus:\\nEl fuego de tu amor me quema\\ncada noche sueño con tenerte\\nesta pasión ardiente nos une\\nnuestro amor es un fuego eterno\\n\\nBridge:\\nPero a pesar de todo\\nsiento que algo nos separa\\nla llama de nuestro amor se apaga\\ny mi corazón se desgarra\\n\\nChorus:\\nEl fuego de tu amor me quema\\ncada noche sueño con tenerte\\nesta pasión ardiente nos une\\nnuestro amor es un fuego eterno\\n\\nOutro:\\nNuestro amor es como una flor\\nque crece fuerte cada día más\\ny aunque a veces hay tormentas\\nnuestro amor nunca se apagará.### Human: I love the way you used metaphors and imagery in the lyrics. Can you add more vivid descriptions of the physical sensations that come with being in a passionate love affair? For example, what does it feel like to be held in the arms of someone you love?### Assistant: Verse 1:\\nCuando tus brazos me envuelven\\nsiento mi cuerpo vibrar\\ntu amor es como una llama ardiente\\nque me llena de felicidad\\n\\nChorus:\\nEl fuego de tu amor me quema\\ncada noche sueño con tenerte\\nesta pasión ardiente nos une\\nnuestro amor es un fuego eterno\\n\\nVerse 2:\\nTu piel es como un cálido abrazo\\nque me hace sentir en casa\\ntus besos son como una explosión\\nque me deja sin aliento, sin voz\\n\\nChorus:\\nEl fuego de tu amor me quema\\ncada noche sueño con tenerte\\nesta pasión ardiente nos une\\nnuestro amor es un fuego eterno\\n\\nBridge:\\nPero a pesar de todo\\nsiento que algo nos separa\\nla llama de nuestro amor se apaga\\ny mi corazón se desgarra\\n\\nChorus:\\nEl fuego de tu amor me quema\\ncada noche sueño con tenerte\\nesta pasión ardiente nos une\\nnuestro amor es un fuego eterno\\n\\nOutro:\\nNuestro amor es un océano\\nque nunca dejará de crecer\\njuntos podemos enfrentar el mundo\\nporque nuestro amor nunca dejará de arder.### Human: This is fantastic so far! Can you add more descriptive language around the physical sensations of desire and yearning that come with being separated from someone you love? Let's really emphasize the intensity of the passion between these two people.### Assistant: Verse 1:\\nCuando tus brazos me envuelven\\nsiento mi cuerpo vibrar\\ny en mi corazón, un gran fuego\\nque nunca dejará de brillar\\n\\nChorus:\\nEl fuego de tu amor me quema\\ncada noche sueño con tenerte\\nesta pasión ardiente nos une\\nnuestro amor es un fuego eterno\\n\\nVerse 2:\\nPero cuando estás lejos, mi amor\\nsiento que muero un poco más\\nmi cuerpo grita tu nombre\\ny mi alma llora tu ausencia, sin paz\\n\\nChorus:\\nEl fuego de tu amor me quema\\ncada noche sueño con tenerte\\nesta pasión ardiente nos une\\nnuestro amor es un fuego eterno\\n\\nBridge:\\nPero a pesar de todo\\nnuestro amor es más fuerte\\nla distancia no nos puede separar\\nporque nuestra pasión siempre va a arder\\n\\nChorus:\\nEl fuego de tu amor me quema\\ncada noche sueño con tenerte\\nesta pasión ardiente nos une\\nnuestro amor es un fuego eterno\\n\\nOutro:\\nNuestro amor es como un volcán\\nque nunca deja de rugir\\nnuestra pasión es ardiente\\ny nunca va a dejar de existir.\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0256807-b22e-47f4-8586-5fae2ca8c66f",
   "metadata": {},
   "source": [
    "### Load Tokenizer & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e785ea2-869b-4014-a52c-00a55c1c6216",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(os.path.join(local_mistral_dir, 'tokenizer'), use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a66633f4-4ebe-47cd-b3a7-69a86fb1f88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<unk>', '<unk>')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.unk_token, tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "316d2b9f-6e65-423c-aa3a-2f7f21908b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.unk_token\n",
    "tokenizer.pad_token_id = tokenizer.unk_token_id\n",
    "tokenizer.padding_side = 'right'   # right, left"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ed597063-e453-4cfe-9e04-25cd3f18d8ec",
   "metadata": {},
   "source": [
    "# tokenizer = LlamaTokenizerFast.from_pretrained(os.path.join(model_dir, 'tokenizer'))   # LlamaTokenizer (x)  -> LlamaTokenizerFast (o)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_dir, torch_dtype=torch.float16, low_cpu_mem_usage=True) # , device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7a586a-5fd2-4983-8a1a-2456f94deed7",
   "metadata": {},
   "source": [
    "#### Quantize model with BitsAndBytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e82774a-e5d6-43c6-9e6d-84d093708437",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_dtype = getattr(torch, \"bfloat16\")   # float16 -> bfloat16 : training more stable \n",
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=compute_dtype,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6286be6-4f68-434c-b10c-e95c48be5626",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /rag/jupyter/llm/../../models/mistral_origin/config.json\n",
      "Model config MistralConfig {\n",
      "  \"_name_or_path\": \"/rag/jupyter/llm/../../models/mistral_origin\",\n",
      "  \"architectures\": [\n",
      "    \"MistralForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"model_type\": \"mistral\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 4096,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.36.2\",\n",
      "  \"use_cache\": false,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file /rag/jupyter/llm/../../models/mistral_origin/model.safetensors.index.json\n",
      "Instantiating MistralForCausalLM model under default dtype torch.float16.\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"use_cache\": false\n",
      "}\n",
      "\n",
      "Detected 4-bit loading: activating 4-bit loading for this model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e10466c8dfe04a2ab90095ee30754f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Load the model and quantize it on the fly\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "      local_mistral_dir, quantization_config=bnb_config, torch_dtype=torch.float16, low_cpu_mem_usage=True, device_map={\"\": 0}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fa380a-5b87-4a48-9077-0a6c0273b686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast some modules of the model to fp32 \n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80ce384-7cfb-4bb9-8f56-ad5efac23019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the pad token in the model\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.use_cache = False # Gradient checkpointing is used by default but not compatible with caching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a5b3e8-b7ad-44d3-ab46-75186e6d6789",
   "metadata": {},
   "source": [
    "### QLoRA Setting (PEFT) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e07cd2d-d369-4098-9b56-978982b0641c",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    r=16,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules= ['k_proj', 'q_proj', 'v_proj', 'o_proj', \"gate_proj\", \"down_proj\", \"up_proj\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abef777c-8004-48d9-bf27-bdbc39cbf311",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments = TrainingArguments(\n",
    "        output_dir=model_path,\n",
    "        #evaluation_strategy=\"steps\",\n",
    "        #do_eval=True,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        per_device_train_batch_size=4,\n",
    "        gradient_accumulation_steps=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        log_level=\"debug\",\n",
    "        save_steps=50,\n",
    "        logging_steps=10,\n",
    "        learning_rate=4e-4,\n",
    "        #eval_steps=200,\n",
    "        num_train_epochs=100,\n",
    "        max_steps=100,\n",
    "        warmup_steps=100,\n",
    "        lr_scheduler_type=\"linear\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0473503a-88e9-45dc-b5ac-ff90f5ad62cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        train_dataset=dataset['train'],\n",
    "        #eval_dataset=dataset['test'],\n",
    "        peft_config=peft_config,\n",
    "        dataset_text_field=\"text\",\n",
    "        max_seq_length=512,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_arguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe29236-c1f1-4e53-8447-200f5580134f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33351d14-57eb-48c9-8a52-3fde0cba4e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_dtype = getattr(torch, \"bfloat16\")   # float16 -> bfloat16 : training more stable \n",
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=compute_dtype,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8df7171-c719-4222-b631-a40a23f66ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and quantize it on the fly\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "      model_dir, quantization_config=bnb_config, torch_dtype=torch.float16, low_cpu_mem_usage=True, device_map={\"\": 0}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ad3dc3-38db-462f-89bd-362c9b9b77d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.use_cache = True\n",
    "model = PeftModel.from_pretrained(model, \"../../models/checkpoint-100/\")   # top layer에 fine-tuned adapter 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5c2d94-16f6-4704-a2f3-084497d93eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(instruction):\n",
    "    prompt = \"### Human: \"+instruction+\"### Assistant: \"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].cuda()\n",
    "    generation_output = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            generation_config=GenerationConfig(pad_token_id=tokenizer.pad_token_id, temperature=1.0, top_p=1.0, top_k=50, num_beams=1),\n",
    "            return_dict_in_generate=True,\n",
    "            output_scores=True,\n",
    "            max_new_tokens=256\n",
    "    )\n",
    "    for seq in generation_output.sequences:\n",
    "        output = tokenizer.decode(seq)\n",
    "        print(output.split(\"### Assistant: \")[1].strip())\n",
    "        \n",
    "generate(\"금융 상품 추천해줘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc890cb-8c72-43a7-929a-75efc5e131a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
